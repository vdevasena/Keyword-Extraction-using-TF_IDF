{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction using TF_IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Data Science Graduate with 2+ years of professional experience in building Machine Learning Models. Coursera certified associate and an enthusiastic team player adept at enhancing predictive modeling, data processing, data mining algorithms and passionate about using my analytical, statistical, and programming skills to collect, analyze, and interpret large data sets, so that by using this information to develop data-driven solutions to complicated business challenges. Worked with many machine learning frameworks such as TensorFlow, Keras, and Scikit-Learn.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Total words in document -- Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = doc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'Science',\n",
       " 'Graduate',\n",
       " 'with',\n",
       " '2+',\n",
       " 'years',\n",
       " 'of',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'building',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Models.',\n",
       " 'Coursera',\n",
       " 'certified',\n",
       " 'associate',\n",
       " 'and',\n",
       " 'an',\n",
       " 'enthusiastic',\n",
       " 'team',\n",
       " 'player',\n",
       " 'adept',\n",
       " 'at',\n",
       " 'enhancing',\n",
       " 'predictive',\n",
       " 'modeling,',\n",
       " 'data',\n",
       " 'processing,',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'using',\n",
       " 'my',\n",
       " 'analytical,',\n",
       " 'statistical,',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'skills',\n",
       " 'to',\n",
       " 'collect,',\n",
       " 'analyze,',\n",
       " 'and',\n",
       " 'interpret',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets,',\n",
       " 'so',\n",
       " 'that',\n",
       " 'by',\n",
       " 'using',\n",
       " 'this',\n",
       " 'information',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'data-driven',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'complicated',\n",
       " 'business',\n",
       " 'challenges.',\n",
       " 'Worked',\n",
       " 'with',\n",
       " 'many',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'frameworks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'TensorFlow,',\n",
       " 'Keras,',\n",
       " 'and',\n",
       " 'Scikit-Learn.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_length = len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Total number of sentences -- Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = tokenize.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Graduate with 2+ years of professional experience in building Machine Learning Models.',\n",
       " 'Coursera certified associate and an enthusiastic team player adept at enhancing predictive modeling, data processing, data mining algorithms and passionate about using my analytical, statistical, and programming skills to collect, analyze, and interpret large data sets, so that by using this information to develop data-driven solutions to complicated business challenges.',\n",
       " 'Worked with many machine learning frameworks such as TensorFlow, Keras, and Scikit-Learn.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sent_len = len(total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sent_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate TF for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': 0.013157894736842105, 'Science': 0.013157894736842105, 'Graduate': 0.013157894736842105, '2+': 0.013157894736842105, 'years': 0.013157894736842105, 'professional': 0.013157894736842105, 'experience': 0.013157894736842105, 'building': 0.013157894736842105, 'Machine': 0.013157894736842105, 'Learning': 0.013157894736842105, 'Models': 0.013157894736842105, 'Coursera': 0.013157894736842105, 'certified': 0.013157894736842105, 'associate': 0.013157894736842105, 'enthusiastic': 0.013157894736842105, 'team': 0.013157894736842105, 'player': 0.013157894736842105, 'adept': 0.013157894736842105, 'enhancing': 0.013157894736842105, 'predictive': 0.013157894736842105, 'modeling,': 0.013157894736842105, 'data': 0.039473684210526314, 'processing,': 0.013157894736842105, 'mining': 0.013157894736842105, 'algorithms': 0.013157894736842105, 'passionate': 0.013157894736842105, 'using': 0.02631578947368421, 'analytical,': 0.013157894736842105, 'statistical,': 0.013157894736842105, 'programming': 0.013157894736842105, 'skills': 0.013157894736842105, 'collect,': 0.013157894736842105, 'analyze,': 0.013157894736842105, 'interpret': 0.013157894736842105, 'large': 0.013157894736842105, 'sets,': 0.013157894736842105, 'information': 0.013157894736842105, 'develop': 0.013157894736842105, 'data-driven': 0.013157894736842105, 'solutions': 0.013157894736842105, 'complicated': 0.013157894736842105, 'business': 0.013157894736842105, 'challenges': 0.013157894736842105, 'Worked': 0.013157894736842105, 'many': 0.013157894736842105, 'machine': 0.013157894736842105, 'learning': 0.013157894736842105, 'frameworks': 0.013157894736842105, 'TensorFlow,': 0.013157894736842105, 'Keras,': 0.013157894736842105, 'Scikit-Learn': 0.013157894736842105}\n"
     ]
    }
   ],
   "source": [
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "print(tf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check if the word is present in a sentence list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sent(word, sentences): \n",
    "    final = [all([w in x for w in word]) for x in sentences] \n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IDF for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': 1.0986122886681098, 'Science': 1.0986122886681098, 'Graduate': 1.0986122886681098, '2+': 1.0986122886681098, 'years': 1.0986122886681098, 'professional': 1.0986122886681098, 'experience': 1.0986122886681098, 'building': 1.0986122886681098, 'Machine': 1.0986122886681098, 'Learning': 1.0986122886681098, 'Models': 1.0986122886681098, 'Coursera': 1.0986122886681098, 'certified': 1.0986122886681098, 'associate': 1.0986122886681098, 'enthusiastic': 1.0986122886681098, 'team': 1.0986122886681098, 'player': 1.0986122886681098, 'adept': 1.0986122886681098, 'enhancing': 1.0986122886681098, 'predictive': 1.0986122886681098, 'modeling,': 1.0986122886681098, 'data': 0.0, 'processing,': 1.0986122886681098, 'mining': 1.0986122886681098, 'algorithms': 1.0986122886681098, 'passionate': 1.0986122886681098, 'using': 0.0, 'analytical,': 1.0986122886681098, 'statistical,': 1.0986122886681098, 'programming': 1.0986122886681098, 'skills': 1.0986122886681098, 'collect,': 1.0986122886681098, 'analyze,': 1.0986122886681098, 'interpret': 1.0986122886681098, 'large': 1.0986122886681098, 'sets,': 1.0986122886681098, 'information': 1.0986122886681098, 'develop': 1.0986122886681098, 'data-driven': 1.0986122886681098, 'solutions': 1.0986122886681098, 'complicated': 1.0986122886681098, 'business': 1.0986122886681098, 'challenges': 1.0986122886681098, 'Worked': 1.0986122886681098, 'many': 1.0986122886681098, 'machine': 1.0986122886681098, 'learning': 1.0986122886681098, 'frameworks': 1.0986122886681098, 'TensorFlow,': 1.0986122886681098, 'Keras,': 1.0986122886681098, 'Scikit-Learn': 1.0986122886681098}\n"
     ]
    }
   ],
   "source": [
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "print(idf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': 0.014455424850896181, 'Science': 0.014455424850896181, 'Graduate': 0.014455424850896181, '2+': 0.014455424850896181, 'years': 0.014455424850896181, 'professional': 0.014455424850896181, 'experience': 0.014455424850896181, 'building': 0.014455424850896181, 'Machine': 0.014455424850896181, 'Learning': 0.014455424850896181, 'Models': 0.014455424850896181, 'Coursera': 0.014455424850896181, 'certified': 0.014455424850896181, 'associate': 0.014455424850896181, 'enthusiastic': 0.014455424850896181, 'team': 0.014455424850896181, 'player': 0.014455424850896181, 'adept': 0.014455424850896181, 'enhancing': 0.014455424850896181, 'predictive': 0.014455424850896181, 'modeling,': 0.014455424850896181, 'data': 0.0, 'processing,': 0.014455424850896181, 'mining': 0.014455424850896181, 'algorithms': 0.014455424850896181, 'passionate': 0.014455424850896181, 'using': 0.0, 'analytical,': 0.014455424850896181, 'statistical,': 0.014455424850896181, 'programming': 0.014455424850896181, 'skills': 0.014455424850896181, 'collect,': 0.014455424850896181, 'analyze,': 0.014455424850896181, 'interpret': 0.014455424850896181, 'large': 0.014455424850896181, 'sets,': 0.014455424850896181, 'information': 0.014455424850896181, 'develop': 0.014455424850896181, 'data-driven': 0.014455424850896181, 'solutions': 0.014455424850896181, 'complicated': 0.014455424850896181, 'business': 0.014455424850896181, 'challenges': 0.014455424850896181, 'Worked': 0.014455424850896181, 'many': 0.014455424850896181, 'machine': 0.014455424850896181, 'learning': 0.014455424850896181, 'frameworks': 0.014455424850896181, 'TensorFlow,': 0.014455424850896181, 'Keras,': 0.014455424850896181, 'Scikit-Learn': 0.014455424850896181}\n"
     ]
    }
   ],
   "source": [
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "print(tf_idf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to get N important words in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 5 words of significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': 0.014455424850896181, 'Science': 0.014455424850896181, 'Graduate': 0.014455424850896181, '2+': 0.014455424850896181, 'years': 0.014455424850896181}\n"
     ]
    }
   ],
   "source": [
    "print(get_top_n(tf_idf_score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
